{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from janitor import clean_names\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train['label'] = 'train'\n",
    "test['label'] = 'test'\n",
    "\n",
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "source": [
    "## Feature Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop identifier features\n",
    "df.drop(columns=['Loan_ID'], inplace=True)\n",
    "\n",
    "# Correct mistyped features\n",
    "df['Loan_Amount_Requested'].replace({',':''}, regex=True, inplace=True)\n",
    "df['Loan_Amount_Requested'] = pd.to_numeric(df['Loan_Amount_Requested'])\n",
    "\n",
    "# 'Month_Since_Deliquency' features contains too many missing values\n",
    "# it might be because the instance doesn't have historical deluquency\n",
    "# solution : derive 'Has_Deliquency' feature as follow\n",
    "# df['Has_Deliquency'] = np.where(df['Months_Since_Deliquency']==np.nan, 0, 1)\n",
    "df.drop(columns=['Months_Since_Deliquency'], inplace=True)\n",
    "\n",
    "# for categorical features, missing values replaced with \"MISSING\"\n",
    "# remaining categorical features with missing values are 'Length_Employed' and 'Home_Owner'\n",
    "df.loc[:,['Length_Employed', 'Home_Owner']].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "df['Length_Employed'].replace({'< 1 year':'less'}, inplace=True)\n",
    "\n",
    "# Replace missing values in Annual Income with mean\n",
    "df['Annual_Income'].fillna(df['Annual_Income'].median(), inplace=True)\n",
    "\n",
    "# Remove outliers\n",
    "# numeric_train = train.select_dtypes(include=np.number).drop(columns=['Interest_Rate'])\n",
    "# abs_z_scores = np.abs(zscore(numeric_train))\n",
    "# filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "# numeric_train = numeric_train[filtered_entries]\n",
    "\n",
    "# New Manual Features\n",
    "df['Monthly_Income'] = df['Annual_Income'] / 12\n",
    "# test['Monthly_Income'] = test['Annual_Income'] / 12\n",
    "\n",
    "df['Accounts_Ratio'] = df['Number_Open_Accounts'] / df['Total_Accounts']\n",
    "#test['Accounts_Ratio'] = test['Number_Open_Accounts'] / test['Total_Accounts']\n",
    "\n",
    "df['Loan_Income_Ratio'] = df['Loan_Amount_Requested'] / df['Annual_Income']\n",
    "# test['Loan_Income_Ratio'] = test['Loan_Amount_Requested'] / test['Annual_Income']\n",
    "\n",
    "#df['Employed_Home'] = df['Length_Employed'] + df['Home_Owner']\n",
    "# test['Employed_Home'] = test['Length_Employed'] + test['Home_Owner']\n",
    "\n",
    "df['Inv_Loan_per_Active_Account'] = df['Number_Open_Accounts'] / df['Loan_Amount_Requested']\n",
    "# test['Loan_per_Active_Account'] = test['Loan_Amount_Requested'] / test['Number_Open_Accounts']\n",
    "\n",
    "df['Loan_per_Total_Account'] = df['Loan_Amount_Requested'] / df['Total_Accounts']\n",
    "# test['Loan_per_Total_Account'] = test['Loan_Amount_Requested'] / test['Total_Accounts']\n",
    "\n",
    "#df['Home_Purpose'] = df['Home_Owner'] + df['Purpose_Of_Loan']\n",
    "# test['Home_Purpose'] = test['Home_Owner'] + test['Purpose_Of_Loan']\n",
    "\n",
    "# Reference: Namvar, Anahita. Credit Risk Prediction in an Imbalanced Social Lending Environment\n",
    "df['NMRA'] = df['Debt_To_Income']*df['Monthly_Income']\n",
    "# test['NMRA'] = test['Debt_To_Income']*test['Monthly_Income']\n",
    "\n",
    "# Reference: Namvar, Anahita. Credit Risk Prediction in an Imbalanced Social Lending Environment\n",
    "df['NDTI'] = df['NMRA'] / df['Monthly_Income']\n",
    "# test['NDTI'] = test['NMRA'] / test['Monthly_Income']\n",
    "\n",
    "#df['Verified_Purpose'] = df['Income_Verified'] + df['Purpose_Of_Loan']\n",
    "# test['Verified_Purpose'] = test['Income_Verified'] + test['Purpose_Of_Loan']\n",
    "\n",
    "# Feature scaling\n",
    "#scaler = StandardScaler()\n",
    "#numeric_df = df.select_dtypes(include=np.number).drop(columns=['Interest_Rate'])\n",
    "#numeric_test = test.select_dtypes(include=np.number)\n",
    "#numeric_df = scaler.fit_transform(numeric_df)\n",
    "#numeric_test = scaler.transform(numeric_test)\n",
    "\n",
    "# OneHotEncoding for Categorical features\n",
    "df = pd.get_dummies(df, columns=[\n",
    "    'Length_Employed', 'Home_Owner',\n",
    "    'Income_Verified', 'Purpose_Of_Loan', 'Gender']\n",
    "    )\n",
    "\n",
    "# cat_df = df.select_dtypes(exclude=np.number)\n",
    "# cat_test = test.select_dtypes(exclude=np.number)\n",
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit_transform(cat_df)\n",
    "#cat_test = encoder.transform(cat_test)\n",
    "\n",
    "# clean column names\n",
    "df = clean_names(df, remove_special=True)\n",
    "\n",
    "# Reset Index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "source": [
    "## Final State of Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['interest_rate'].abs().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "## Data Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['label'] == 'train'].copy()\n",
    "train.drop(columns=['label'], inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test = df[df['label'] == 'test'].copy()\n",
    "test.drop(columns=['interest_rate', 'label'], inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "source": [
    "## Export Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment code to export data\n",
    "train.to_csv('../data/train_ready.csv', index=False)\n",
    "test.to_csv('../data/test_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "## Data Split 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['interest_rate'])\n",
    "y = train['interest_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Resampling\n",
    "# resampler = RandomUnderSampler()\n",
    "# X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_models = {\n",
    "    'sgdc' : SGDClassifier(),\n",
    "    'ridge' : RidgeClassifier(),\n",
    "    'rf' : RandomForestClassifier(),\n",
    "    'autoskl' : AutoSklearnClassifier(memory_limit=8*1024),\n",
    "    'gbc' : GradientBoostingClassifier(),\n",
    "    'hgbc' : HistGradientBoostingClassifier(),\n",
    "    'xgboost' : XGBClassifier(),\n",
    "    'lgbm' : LGBMClassifier(),\n",
    "    'catboost' : CatBoostClassifier(silent=True)\n",
    "}\n",
    "\n",
    "for name, model in classifier_models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #y_prob = model.predict_proba(X_test)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}